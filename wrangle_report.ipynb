{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this report I talked about my experience on wrangle project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "I gathered, cleaned, and analyzed an interesting dataset on Python: WeRateDogs tweets. First, let me introduce you to this famous Twitter account. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because [\"they're good dogs Brent.\"](https://knowyourmeme.com/memes/theyre-good-dogs-brent) WeRateDogs has over 4 million followers and has received international media coverage. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather\n",
    "I worked on three datasets:\n",
    "1. Enhanced twitter dataset: The dataset that I have worked on contains basic tweet data (tweet ID, timestamp, text, etc.) for all 5000+ of their tweets as they stood on August 1, 2017. Using post text, dog names, ratings and dog stages are extracted. I downloaded the given csv file for the dataset. \n",
    "2. Retweet and favorite counts dataset: I downloaded retweet and favorite counts for the tweets from Twitter's database. Actually, there is an issue so I had to use prepared json file. \n",
    "3. Predicted breeds dataset: Using images from tweets, a machine learning algorithm predicted the breed of the dog, and I also used this dataset. With request library, I created a request and download dataset as tsv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess\n",
    "After gathering these three datasets, I started assessing. Firstly, I visualy assessed the table. I saw that there are a lot of missing dog stages and they were stated as \"None\". Also, although these dog stages can be counted as just one variable they were allocating three seperate columns, which causes a tidiness issue. Secondly, I saw that there were some retweet data that we do not want. Another issue is that we had separate denominator and numerator columns for rating. <br>\n",
    "To saw \"None\" and missing values I programatically assessed table. Using .info and .describe commands I checked type of the columns and detected that count values are not int and tweet_id was stored as integer rather than string. <br>\n",
    "Lastly, I documented all of these and moved on to the cleaning part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean\n",
    "To make cleaning process structured, I used describe-code-test framework. Using issues that I have pointed out in assessing part, I created some call to actions in describe part. Then I coded some code segments to implement describe parts. To find missing values I checked the entires with \"None\" values or NaN. Since \"None\" values are counted as strings I converted them to np.nan. To find erronous names, I tried to detect a pattern and realized that all dog names are starting with capital letters. So, I eliminated lowercase lettered dog names. In addition, some rating numerators had decimal values in real tweet text. However, they were extracted as int and of course wrong values. I detected them with a regex code and then changed them. After coding part I checked whether my table is correctly implemented or not. <br>\n",
    "In predicted breed dog table, there were a lot of mispredicted values. However, there is no easy way to handle them so I left them as they are and just picked the most likely prediction.\n",
    "Mostly, after the test stage I also coded another commands to make dataset more tidy. For example, I dropped the columns after checking the new column were created correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary / Conclusion\n",
    "\n",
    "After reaching a clean dataset, I started analyzing the results. Firstly I wondered about the common dog names. Analyzing dog names' value counts, I saw that the most common three dog names are Charlie, Oliver, and Lucy. Secondly, I checked the dog breed with the highest rating. I grouped dog breeds and visualy found the first highest non erronous dog prediction. Saluki breed type has the highest rating average with 1.25. Thirdly, I looked for common breeds to see the most popular breeds. Again using value counts in the column, the most common three dog breeds are Golden Retriever, Labrador Retriever, and Pembroke. <br>\n",
    "\n",
    "Lastly, I wanted to see whether there is a relation between dog ratings and favorite counts. Maybe higher ratings grab higher favorites. When I plotted, I observed a slight relation, maybe do not deserve mentioning, but there is a week relation: higher ratings grab higher fav. counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook wrangle_report.ipynb to html\n",
      "[NbConvertApp] Writing 281134 bytes to wrangle_report.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html wrangle_report.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
