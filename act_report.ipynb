{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report: act_report\n",
    ""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This weekend I gathered, cleaned, and analyzed an interesting dataset on Python: WeRateDogs tweets! First, let me introduce you to this famous Twitter account if you have not heard it before. <br>\n",
    "WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because [\"they're good dogs Brent.\"](https://knowyourmeme.com/memes/theyre-good-dogs-brent) WeRateDogs has over 4 million followers and has received international media coverage. <br>\n",
    "Interesting, right? Maybe you might wonder what kind of data I can have about this account. <br>\n",
    "The dataset that I have worked on contains basic tweet data (tweet ID, timestamp, text, etc.) for all 5000+ of their tweets as they stood on August 1, 2017. Using post text, dog names, ratings and dog stages are extracted. Also, I downloaded retweet and favorite counts for the tweets from Twitter's database. And, one more cool thing: using images from tweets, a machine learning algorithm predicted the breed of the dog, and I also used this dataset!. <br>\n",
    "However, life is not that easy in data science! The datasets that I want to use and analyze accounts are not clean. In other words, datasets were not ready to work directly on them. Firstly I had to clean and tidy up them; after that, I could analyze their meanings. <br>\n",
    "So I started cleaning the data sets. There were erroneous dog names, missing Twitter URLs, and some unnecessary information. I cleaned all of them and created a tidy twitter dataset. If we come to our predicted dog breeds table... Well, it has not gone well. Because our machine learning algorithm sometimes predicted the dog breed as toilet paper. Yeah, you read it correctly. <br>\n",
    "After reaching a clean dataset, I started analyzing the results. Firstly I wondered about the common dog names. Analyzing tweets, I saw that the most common three dog names are Charlie, Oliver, and Lucy. Secondly, I wanted to see whether there is a relation between dog ratings and favorite counts. Maybe higher ratings grab higher favorites, right? When I drew a plot, I observed a slight relation, maybe do not deserve mentioning, you can decide by checking the plot below, but anyway, there is a relation: higher ratings grab higher fav. counts. Moreover, I checked the dog breed with the highest rating! Saluki breed type has the highest rating average with 1.25. Lastly, I looked for common breeds to see the most popular breeds. The most common three dog breeds are Golden Retriever, Labrador Retriever, and Pembroke. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](plot.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook act_report.ipynb to html\n",
      "[NbConvertApp] Writing 277725 bytes to act_report.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html act_report.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
